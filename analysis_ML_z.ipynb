{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d75bed7d",
   "metadata": {},
   "source": [
    "# Delta Radiomics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ee16bc",
   "metadata": {},
   "source": [
    "### **Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b5d289",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd84a375",
   "metadata": {},
   "source": [
    "### **Import Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed7db61",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"D:/DSLS/Omics2/integromics/config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187b6c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_delta_radiomics(data_folder_path):\n",
    "    \"\"\"\n",
    "    Reads radiomics data from subfolders (Time A and Time B), filters for 'suv2.5' \n",
    "    segmentation, calculates the delta (B - A) for numeric features, and stores\n",
    "    the results in a dictionary per patient.\n",
    "\n",
    "    Args:\n",
    "        data_folder_path (str): The path to the main folder containing patient subfolders.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are patient folder names (Patient IDs) \n",
    "              and values are dictionaries containing the calculated delta radiomics features.\n",
    "    \"\"\"\n",
    "    all_delta_radiomics = {}\n",
    "    A_radiomics, B_radiomics = {}, {}\n",
    "\n",
    "    # 1. Iterate through all items in the main data folder\n",
    "    for patient_folder_name in os.listdir(data_folder_path):\n",
    "        patient_path = os.path.join(data_folder_path, patient_folder_name)\n",
    "        \n",
    "        # Ensure it is actually a directory (a patient folder)\n",
    "        if os.path.isdir(patient_path):\n",
    "            print(f\"--- Processing {patient_folder_name} ---\")\n",
    "            \n",
    "            # Initialize paths for Time A and Time B files\n",
    "            file_A_path = None\n",
    "            file_B_path = None\n",
    "            \n",
    "            # 2. Find the radiomics files for Time A and Time B in the patient folder\n",
    "            for filename in os.listdir(patient_path):\n",
    "                path_excel = os.path.join(patient_path, filename)\n",
    "                # NOTE: Assuming the files are named consistently and contain 'A' or 'B' \n",
    "                # to identify the time point. Adjust this logic if needed.\n",
    "  \n",
    "                if '_A' in path_excel.upper() and path_excel.endswith('.xlsx'):\n",
    "                        file_A_path = path_excel\n",
    "                elif '_B' in path_excel.upper() and path_excel.endswith('.xlsx'):\n",
    "                        file_B_path = path_excel\n",
    "            if file_A_path and file_B_path:\n",
    "                try:\n",
    "                    # 3. Read and preprocess the data\n",
    "                    \n",
    "                    # Read Excel files and transpose them (assuming features are in columns \n",
    "                    # and metadata/values in rows; pandas reads the first row as header)\n",
    "                    # We assume 'segmentation' is one of the columns after reading.\n",
    "                    df_A = pd.read_excel(file_A_path)\n",
    "                    df_B = pd.read_excel(file_B_path)\n",
    "                    \n",
    "                    # 4. Filter for the 'suv2.5' segmentation row\n",
    "                    # NOTE: the column containing 'suv2.5' is named 'Segmentation'\n",
    "                    # and the feature names are in the other columns.\n",
    "                    # filtering the columns fro 23 onwards to get only feature values\n",
    "                    row_A = df_A[df_A['Segmentation'].str.contains('suv2.5')].iloc[0, 23:]\n",
    "                    row_B = df_B[df_B['Segmentation'].str.contains('suv2.5')].iloc[0, 23:]\n",
    "\n",
    "                    # Create a Series of only the numeric feature values for A and B\n",
    "                    \n",
    "                    # Convert to numeric, coercing errors to NaN (just in case)\n",
    "                    numeric_A = pd.to_numeric(row_A, errors='coerce')\n",
    "                    numeric_B = pd.to_numeric(row_B, errors='coerce')\n",
    "\n",
    "                    # 6. Calculate Delta Radiomics (Time B - Time A)\n",
    "                    delta_radiomics = numeric_B - numeric_A\n",
    "                    \n",
    "                    \n",
    "                    # Convert the resulting pandas Series into a standard Python dictionary\n",
    "                    # and store it under the patient's ID\n",
    "                    # dropna() to remove any features that resulted in NaN\n",
    "                    all_delta_radiomics[patient_folder_name] = delta_radiomics.dropna().to_dict()\n",
    "                    A_radiomics[patient_folder_name] = numeric_A.dropna().to_dict()\n",
    "                    B_radiomics[patient_folder_name] = numeric_B.dropna().to_dict()\n",
    "                    print(f\"Successfully calculated radiomics and delta radiomics for {patient_folder_name}.\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing files for {patient_folder_name}: {e}\")\n",
    "            else:\n",
    "                print(f\"Could not find both A and B files in {patient_folder_name}.\")\n",
    "    A = pd.DataFrame.from_dict(A_radiomics, orient='index')\n",
    "    B = pd.DataFrame.from_dict(B_radiomics, orient='index')\n",
    "    all_delta_radiomics = pd.DataFrame.from_dict(all_delta_radiomics, orient='index')\n",
    "\n",
    "    return all_delta_radiomics, A, B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1002aff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to main data folder\n",
    "\n",
    "DATA_DIR = config[\"data\"][\"root_dir\"]\n",
    "\n",
    "# Run the function\n",
    "delta_radiomics_results, a_radiomics, b_radiomics = calculate_delta_radiomics(DATA_DIR)\n",
    "\n",
    "# Print the results for verification\n",
    "print(\"\\n--- Final Results Summary ---\")\n",
    "for patient, delta_data in delta_radiomics_results.items():\n",
    "    print(f\"\\n{patient} Delta Radiomics ({len(delta_data)} features):\")\n",
    "    # Print the first 5 features as an example\n",
    "    print(dict(list(delta_data.items())[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4627bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_radiomics_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b961fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and prepare dataframes\n",
    "# by dropping columns with any NaN values and resetting index\n",
    "# to keep only the complete cases (some patients have 99 columns with NaNs, but 43 are always present)\n",
    "# we'll work with those 43.\n",
    "for df in [delta_radiomics_results, a_radiomics, b_radiomics]:\n",
    "    df.dropna(axis=1, how='any', inplace=True)\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={'index': 'id'}, inplace=True)\n",
    "    df['id'] = df['id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b85408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to differentiate the columns of A and B datasets\n",
    "a_radiomics = a_radiomics.add_suffix('_a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce52df49",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a_radiomics.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5514fcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_radiomics = b_radiomics.add_suffix('_b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a012303",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(b_radiomics.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09464ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for patient, delta_data in delta_radiomics_results.items():\n",
    "    if len(delta_data) == 99:\n",
    "        print(patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178d4edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_results = {patient: data for patient, data in delta_radiomics_results.items() if len(data) != 99}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd07748",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filtered_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500a2f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "for patient, delta_data in delta_radiomics_results.items():\n",
    "        print(patient)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19daf818",
   "metadata": {},
   "source": [
    "Other than Kylies folders, we're missing these:  \n",
    "**12: missing folder A**  \n",
    "**19: missing results for A**  \n",
    "**21: missing folder B**  \n",
    "**64: missing results for B**  \n",
    "\n",
    "Therefore we're left with only 14 complete delta radiomics feature sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e059bbfc",
   "metadata": {},
   "source": [
    "# Clinical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64249519",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clinical_dir = config[\"clinical\"][\"root_dir\"]      # \"D:/DSLS/Omics2/modelling/clinical_data\"\n",
    "clinical_file = config[\"clinical\"][\"main_file\"]    # \"10162025_UMCG_wide_export_Yescarta_infused_for_tFL_study.xlsx\"\n",
    "\n",
    "clinical_path = os.path.join(clinical_dir, clinical_file)\n",
    "clinic_data = pd.read_excel(clinical_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04d9278",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinic_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba80264",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c94a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinic_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c03f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinic_data['record_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e47c367",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinic_data['id_cleaned'] = [value[-3:] for value in clinic_data['record_id'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c204902f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinic_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117e25aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2827a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinic_data['id_cleaned'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9be641",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_radiomics_results['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9350633",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_ids = clinic_data['id_cleaned'].values[1:].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc96be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find patients that are in both datasets\n",
    "# values starts from 1 to skip the comment row\n",
    "intercept = [id for id in delta_radiomics_results['id'] if id in patient_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f159bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinic_data['id_cleaned'] = ['ID'] + patient_ids.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21d7a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinic_data_cleaned = clinic_data[clinic_data['id_cleaned'].isin(intercept)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc45cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinic_data_cleaned.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d28289",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinic_data_cleaned.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c81b67c",
   "metadata": {},
   "source": [
    "Eventually, we have 24 patients with complete clinical and delta radiomics data to work with.\n",
    "\n",
    "**Note:** patient 95 is missing their clinical data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4676e5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we now should select features we need for modelling the baseline, without the delta radiomics\n",
    "clinic_data_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910285f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping columns with all NaN values\n",
    "clinic_data_cleaned = clinic_data_cleaned.dropna(axis=1, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d80befe",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinic_data_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00ee877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we don't need factor columns for modelling as they are encoded already\n",
    "factors = [factor for factor in clinic_data_cleaned.columns if 'factor' in factor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37512acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = [comm for comm in clinic_data_cleaned.columns if 'comment' in comm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171c6298",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb06559",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = [loc for loc in clinic_data_cleaned.columns if 'loc' in loc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bfeb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c2495c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are highly correlated features with bmi\n",
    "correlated = ['scr_height', 'scr_weight']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ca5d05",
   "metadata": {},
   "source": [
    "* scr_age (continuous) correlates to indication_age_60 (binary), we Keep scr_age (continuous). It retains more information and doesn't arbitrarily cut at 60.  \n",
    "* indication_ldh_uln: we have the exact value for ldh  \n",
    "* indication_extran_sites, indication_extran_invol, indication_extranodal_nr\tThese are highly related. we keep indication_extranodal_nr (exact number). It is the most granular quantitative measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5a5882",
   "metadata": {},
   "outputs": [],
   "source": [
    "indicators = ['indication_ldh_uln','indication_age_60','indication_extran_sites', 'indication_extran_invol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce70c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cause of death columns are not needed\n",
    "cause_of_death = [cause for cause in clinic_data_cleaned.columns if '_cause' in cause]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2329210",
   "metadata": {},
   "outputs": [],
   "source": [
    "cause_of_death"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15d1415",
   "metadata": {},
   "source": [
    "**NOTE:** indication_dis_diagnosis must be one-hot encoded. as the disease is a nominal categorical feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a83c5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "disease = pd.get_dummies(clinic_data_cleaned['indication_dis_diagnosis.factor']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b47d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0499127",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = cause_of_death + factors + ['record_id','scr_date_tb1stmeeting', 'indication_dis_diagnosis'] + comments + locations + correlated + indicators\n",
    "clinic_data_cleaned.drop(columns=drop_columns,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fb2826",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinic_data_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f41bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinic_data_cleaned = pd.concat([clinic_data_cleaned, disease], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e425d7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinic_data_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56610385",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinic_data_cleaned.replace({'NE': np.nan}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4303a0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinic_data_cleaned.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd07f50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nans = clinic_data_cleaned.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923dbcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns with more than 12 nans, which is half the data for the patients we have\n",
    "nans[nans > 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ef3977",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_nans = nans[nans > 12].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f08a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinic_data_cleaned = clinic_data_cleaned.drop(columns=drop_nans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d8c23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinic_data_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67407c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinic_data_cleaned.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c8ce2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinic_data_cleaned.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2559a247",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinic_data_cleaned.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d56e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming clinic_data_filtered is the DataFrame you want to convert\n",
    "date_columns = [date for date in clinic_data_cleaned.columns if ('date' in date) or ('start' in date) or ('stop' in date)]\n",
    "# 1. Use convert_dtypes() for general automatic inference\n",
    "# This function automatically converts to best possible dtypes (e.g., object to string, int64 to Int64, float64 to Float64)\n",
    "# It's particularly useful for handling missing values using pandas' nullable dtypes (e.g., pd.NA).\n",
    "print(\"Applying general type conversion...\")\n",
    "\n",
    "# 2. Force remaining object columns that look like numbers to numeric\n",
    "for col in clinic_data_cleaned.columns:\n",
    "        if col not in date_columns:\n",
    "            # Attempt to convert to numeric.\n",
    "            # this is to fix a typo in columns where , is used instead of .\n",
    "            if clinic_data_cleaned[col].dtype == 'object':\n",
    "                clinic_data_cleaned[col] = pd.to_numeric(clinic_data_cleaned[col].str.replace(',','.'), errors='raise')\n",
    "            print(f\"  Converted column '{col}' to numeric.\")\n",
    "        else: \n",
    "            clinic_data_cleaned[col] = pd.to_datetime(clinic_data_cleaned[col], errors='coerce')\n",
    "            print(f\"  Converted column '{col}' to datetime.\")\n",
    "        \n",
    "print(\"\\nAutomatic type conversion complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a2bbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinic_data_cleaned.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da99905",
   "metadata": {},
   "outputs": [],
   "source": [
    "variances = clinic_data_cleaned.select_dtypes(include=np.number).var().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94751c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero variance columns are not useful for modelling so I am dropping them\n",
    "zero_var = variances[variances == 0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197da1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321e3029",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinic_data_cleaned = clinic_data_cleaned.drop(columns=zero_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464d4e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinic_data_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444872b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinic_data_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dd9651",
   "metadata": {},
   "source": [
    "CRS and ICANS are two of the most significant and potentially life-threatening side effects associated with certain powerful immunotherapies, most notably CAR T-cell therapy (Chimeric Antigen Receptor T-cell therapy).\n",
    "\n",
    "\n",
    "ðŸ’¥ 1. Cytokine Release Syndrome (CRS)\n",
    "CRS is the more common of the two toxicities and is essentially a massive, systemic inflammatory response.\n",
    "\n",
    "What it is: When the modified CAR T-cells successfully attack cancer cells, they rapidly multiply and release large amounts of signaling molecules called cytokines into the bloodstream (hence the name \"Cytokine Release Syndrome\"). This rapid, massive release causes a widespread inflammatory state.\n",
    "\n",
    "Symptoms: CRS symptoms resemble a severe flu:\n",
    "\n",
    "High fever (the hallmark symptom)\n",
    "\n",
    "Chills, muscle aches, and fatigue\n",
    "\n",
    "Hypotension (low blood pressure)\n",
    "\n",
    "Hypoxia (low oxygen/trouble breathing)\n",
    "\n",
    "Fast heart rate (tachycardia)\n",
    "\n",
    "In severe cases, it can lead to multi-organ failure.\n",
    "\n",
    "The severity of CRS (often graded 1 to 4/5 by consensus guidelines like the ASTCT criteria) is a crucial prognostic factor.\n",
    "\n",
    "ðŸ§  2. Immune Effector Cell-Associated Neurotoxicity Syndrome (ICANS)\n",
    "ICANS is a syndrome involving neurological damage or dysfunction caused by the same immune activation that triggers CRS.\n",
    "\n",
    "What it is: It is a neurological toxicity that typically occurs after or concurrently with CRS. The exact mechanism is complex but involves the massive cytokine release and the T-cells themselves affecting the central nervous system.\n",
    "\n",
    "Symptoms: ICANS symptoms can range from mild to life-threatening:\n",
    "\n",
    "Confusion or disorientation\n",
    "\n",
    "Aphasia (difficulty speaking or understanding language)\n",
    "\n",
    "Impaired attention\n",
    "\n",
    "Headache, tremors, or loss of coordination\n",
    "\n",
    "In severe cases, it can cause seizures or cerebral edema (brain swelling).\n",
    "\n",
    "ICANS severity is also graded using specific neurological assessment scores and is a very strong independent predictor of outcomes and morbidity after CAR T-cell therapy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb57a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinic_data_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0730d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinic_data_cleaned.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c94572b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values with the median for numeric columns\n",
    "for col in clinic_data_cleaned.select_dtypes(include=np.number).columns:\n",
    "    median_value = clinic_data_cleaned[col].median()\n",
    "    clinic_data_cleaned[col].fillna(median_value, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0c638a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinic_data_cleaned.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0faa0d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are date related column that still have nans, but we will not use them for modelling as we can't impute them easily\n",
    "# also cli_st_lab_date is not needed\n",
    "date_columns = [\n",
    "    'indication_ind_date',\n",
    "    'tr_car_inf_adm_date',\n",
    "    'tr_car_ld_start',\n",
    "    'tr_car_inf_date',\n",
    "    'tr_car_inf_discharge_date',\n",
    "    'ae_summ_start_date_v2',\n",
    "    'ae_summ_crs_start_v2',\n",
    "    'ae_summ_crs_stop_v2',\n",
    "    'surv_prog_date',\n",
    "    'surv_date',\n",
    "    'cli_st_lab_date'\n",
    "]\n",
    "\n",
    "clinic_data_cleaned.drop(columns=date_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7f0419",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinic_data_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a348b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinic_data_cleaned.isna().sum().sum() # confirming no nans remain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76c2d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinic_data_cleaned.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b144aef3",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182c22ae",
   "metadata": {},
   "source": [
    "## Calculate Time-to-Event (T) to prepare for Cox Regression\n",
    "\n",
    "We need to select one pair of dates to calculate the duration of follow-up (Time, or $T$).  \n",
    "Choice: The standard time point for post-therapy outcomes is from the date of infusion to the date of follow-up/death.  \n",
    "Start Date: tr_car_inf_date (Date of CAR-T infusion)  \n",
    "End Date: surv_date (Date of last follow-up or death)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7410bdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate the Time-to-Event (T) in days\n",
    "# # This is the time from infusion until the event (or censoring)\n",
    "# clinic_data_cleaned['T'] = (\n",
    "#     clinic_data_cleaned['surv_date'] - clinic_data_cleaned['tr_car_inf_date']\n",
    "# ).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb78376",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinic_data_cleaned['T']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9427e3",
   "metadata": {},
   "source": [
    "## Define the Event Indicator (E)\n",
    "\n",
    "We need a binary variable (Event, or $E$) that indicates if the event of interest occurred.Choice: The most common target is Overall Survival (OS), where the event is death.Event Variable: surv_status (Assuming this is a 0/1 indicator where 1 = death/event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40215072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the dataset, it's the opposite of what we want: 1 means event occurred (death), 0 means censored (alive)\n",
    "# so we need to invert it\n",
    "clinic_data_cleaned['surv_status'] = 1 - clinic_data_cleaned['surv_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdc6a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename surv_status to E for event\n",
    "clinic_data_cleaned.rename(columns={'surv_status': 'E'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decc9f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinic_data_cleaned['E']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9be8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we should separate the possible target variables for modelling now\n",
    "target_variables = ['surv_time_bestresponse_car', 'surv_prog_after_car']\n",
    "date_related = ['tr_car_inf_adm_date','tr_car_ld_start', 'tr_car_inf_date', 'tr_car_inf_discharge_date',\n",
    "       'ae_summ_start_date_v2','surv_date','indication_ind_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146d50db",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelling_data = pd.concat([clinic_data_cleaned, delta_radiomics_results, a_radiomics, b_radiomics], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3bdddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelling_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b89386a",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelling_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ff8473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to drop the last row, as the patient's clinical data is not available\n",
    "modelling_data = modelling_data.iloc[:-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c149fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to find the baseline performance, we don't need id_cleaned as we're not going to\n",
    "# use this column for adding the delta radiomics yet\n",
    "X = modelling_data.drop(columns=target_variables + date_related + ['id_a','id_b','id_cleaned','id'])                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c394dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7e5b12",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3b1470",
   "metadata": {},
   "source": [
    "# **ML Modelling**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9e9f78",
   "metadata": {},
   "source": [
    "### **KNN Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbbeb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, VarianceThreshold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer \n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6382c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_delta_radiomics = pd.concat([clinic_data_cleaned, a_radiomics, b_radiomics], axis=1)\n",
    "no_delta_radiomics = no_delta_radiomics.iloc[:-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5427a509",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_with_delta = modelling_data.drop(columns=target_variables + date_related + ['T','E','id_a','id_b','id_cleaned','id']) \n",
    "\n",
    "X_without_delta = no_delta_radiomics.drop(columns=target_variables + date_related + ['T', 'E', 'id_a','id_b','id_cleaned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab89b426",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = modelling_data['E']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909621cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "\n",
    "K_BEST_OPTIONS = [5, 10, 20] # a range of k values to try in the grid search\n",
    "\n",
    "VAR_THRSH = [0.1, 0.5, 1.0] # variance threshold options to try in grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3934b04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_radio = a_radiomics.columns[1:].tolist() + b_radiomics.columns[1:].tolist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f784a18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS_TO_SCALE_WITH_DELTA = ['scr_age', 'scr_bmi', 'cli_st_trombocytes', 'cli_st_neutrophils','cli_st_ldh', 'cli_st_crp', 'cli_st_ferritin' ] + scale_radio + delta_radiomics_results.columns[1:].tolist()\n",
    "\n",
    "COLUMNS_TO_SCALE_WITHOUT_DELTA = ['scr_age', 'scr_bmi', 'cli_st_trombocytes', 'cli_st_neutrophils','cli_st_ldh', 'cli_st_crp', 'cli_st_ferritin' ] + scale_radio\n",
    "\n",
    "COLUMNS_TO_SCALE_NO_RADIO = ['scr_age', 'scr_bmi', 'cli_st_trombocytes', 'cli_st_neutrophils','cli_st_ldh', 'cli_st_crp', 'cli_st_ferritin' ]\n",
    "\n",
    "COLUMNS_TO_SCALE_ONLY_POINT_A = ['scr_age', 'scr_bmi', 'cli_st_trombocytes', 'cli_st_neutrophils','cli_st_ldh', 'cli_st_crp', 'cli_st_ferritin' ] + a_radiomics.columns[1:].tolist()\n",
    "COLUMNS_TO_SCALE_ONLY_POINT_B = ['scr_age', 'scr_bmi', 'cli_st_trombocytes', 'cli_st_neutrophils','cli_st_ldh', 'cli_st_crp', 'cli_st_ferritin' ] + b_radiomics.columns[1:].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43758c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "only_clinic = clinic_data_cleaned.drop(columns=target_variables + date_related + ['id_cleaned','E','T'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e13ad71",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_with_a_radiomics = pd.concat([only_clinic, a_radiomics], axis=1).iloc[:-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bca2a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_with_b_radiomics = pd.concat([only_clinic, b_radiomics], axis=1).iloc[:-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2c4cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, X, COLUMNS_TO_SCALE in [(\"with delta radiomics features\", X_with_delta, COLUMNS_TO_SCALE_WITH_DELTA), \n",
    "                                  (\"without delta radiomics features\", X_without_delta, COLUMNS_TO_SCALE_WITHOUT_DELTA), \n",
    "                                  (\"only clinical features\", only_clinic, COLUMNS_TO_SCALE_NO_RADIO),\n",
    "                                  (\"only clinical + point A radiomics\", X_with_a_radiomics, COLUMNS_TO_SCALE_ONLY_POINT_A),\n",
    "                                  (\"only clinical + point B radiomics\", X_with_b_radiomics, COLUMNS_TO_SCALE_ONLY_POINT_B)]:\n",
    "    print(\"\\n\" + \"=\"*20)\n",
    "    print(f\"Starting new modelling run: {name}\")\n",
    "    print(\"=\"*20 + \"\\n\")\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    # Define the ColumnTransformer for selective scaling\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            # Apply StandardScaler only to the specified list of columns\n",
    "            ('scaling_pipeline', StandardScaler(), COLUMNS_TO_SCALE)\n",
    "        ],\n",
    "        # 'remainder='passthrough' is crucial: it keeps all other columns untouched\n",
    "        remainder='passthrough' \n",
    "    )\n",
    "    # Step 1: Feature Scaling (Crucial for SVMs)\n",
    "    scaler = StandardScaler()\n",
    "    # Step 2: Variance Threshold (New Step)\n",
    "    # Removes features whose variance is below the threshold.\n",
    "    # This step helps pre-filter non-informative features before SelectKBest.\n",
    "    variance_filter = VarianceThreshold()\n",
    "    # Step 3: Feature Selection\n",
    "    # Use SelectKBest with f_classif (ANOVA F-value)\n",
    "    feature_selector = SelectKBest(score_func=f_classif)\n",
    "\n",
    "    # Step 4: Classifier\n",
    "    # Using a 'linear' kernel is often more stable than RBF when N is small and P is large.\n",
    "    # Note: The C parameter will be tuned using GridSearchCV.\n",
    "    classifier = KNeighborsClassifier()\n",
    "    #SVC(random_state=RANDOM_STATE)\n",
    "\n",
    "    # Build the pipeline with the new scaling and threshold steps\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocess', preprocessor),                 # Standardize features first\n",
    "        ('variance_threshold', variance_filter),\n",
    "        ('select_kbest', feature_selector), \n",
    "        ('classifier', classifier)      \n",
    "    ])\n",
    "\n",
    "    print(\"Pipeline updated, now includes StandardScaler and VarianceThreshold for initial feature filtering.\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "\n",
    "    # --- 3. Hyperparameter Tuning with GridSearchCV ---\n",
    "\n",
    "    # Define the parameter grid to search over.\n",
    "\n",
    "\n",
    "    param_grid = {\n",
    "\n",
    "        'variance_threshold__threshold': VAR_THRSH,\n",
    "        # Tuning the 'k' parameter of SelectKBest (how many features to select)\n",
    "        'select_kbest__k': K_BEST_OPTIONS,\n",
    "        # Tuning the 'C' regularization parameter of the SVC\n",
    "        'classifier__n_neighbors': [3, 4, 5] \n",
    "        }\n",
    "    \n",
    "    # Use GridSearchCV with the pipeline and the parameter grid.\n",
    "    # The inner Cross-Validation (cv=5) ensures stable feature selection.\n",
    "    # The pipeline ensures feature selection is ONLY fitted on the training folds.\n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline, \n",
    "        param_grid, \n",
    "        cv=5,                 # Use 5-fold cross-validation\n",
    "        scoring='accuracy',   # Metric to optimize\n",
    "        n_jobs=-1             # Use all available cores\n",
    "    )\n",
    "\n",
    "    print(\"Starting Grid Search training...\")\n",
    "    grid_search.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "    # --- 4. Evaluate the Best Model ---\n",
    "\n",
    "    print(\"\\nGrid Search Complete.\")\n",
    "    print(f\"Best parameters found: {grid_search.best_params_}\")\n",
    "    print(f\"Best cross-validation score (Training Set): {grid_search.best_score_:.4f}\")\n",
    "\n",
    "    # Predict on the held-out test data using the best estimator found by GridSearchCV\n",
    "    y_pred = grid_search.predict(x_test)\n",
    "\n",
    "    # Evaluate performance on the test set\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Test Accuracy (unseen data): {accuracy:.4f}\")\n",
    "\n",
    "\n",
    "    # --- 5. Inspecting the Feature Selection Results of the Best Model ---\n",
    "\n",
    "    best_selector = grid_search.best_estimator_['select_kbest']\n",
    "    scores = best_selector.scores_\n",
    "    p_values = best_selector.pvalues_\n",
    "    k_best = grid_search.best_params_['select_kbest__k']\n",
    "    all_features = x_train.columns.tolist()\n",
    "\n",
    "    # 5.1 Determine the order of features after the ColumnTransformer\n",
    "    # ColumnTransformer puts the transformed columns first, then the remainder.\n",
    "    passthrough_features = [col for col in all_features if col not in COLUMNS_TO_SCALE]\n",
    "    full_feature_names_after_preprocessor = COLUMNS_TO_SCALE + passthrough_features\n",
    "\n",
    "    # 5.2 Apply the variance mask to the ordered list of feature names\n",
    "    best_variance_filter = grid_search.best_estimator_['variance_threshold']\n",
    "    variance_mask = best_variance_filter.get_support()\n",
    "    features_after_variance_filter = np.array(full_feature_names_after_preprocessor)[variance_mask].tolist()\n",
    "\n",
    "    # 5.3 Create a DataFrame to sort and display all feature scores from SelectKBest\n",
    "    feature_ranking = pd.DataFrame({\n",
    "        'Feature': features_after_variance_filter,\n",
    "        'F_Score': scores,\n",
    "        'P_Value': p_values\n",
    "    })\n",
    "\n",
    "    # Sort by F_Score (highest first) and print the top K\n",
    "    feature_ranking = feature_ranking.sort_values(by='F_Score', ascending=False)\n",
    "    top_k_features = feature_ranking.head(k_best)\n",
    "\n",
    "\n",
    "    print(\"\\n--- Feature Ranking by SelectKBest (Best Model) ---\")\n",
    "    print(f\"Optimal Variance Threshold used: {grid_search.best_params_['variance_threshold__threshold']:.2f}\")\n",
    "    print(f\"Number of features remaining after Variance Threshold: {len(features_after_variance_filter)}\")\n",
    "    print(f\"Optimal number of features (k) chosen by SelectKBest: {k_best}\")\n",
    "\n",
    "    # Display the top features, scores, and p-values\n",
    "    print(top_k_features.to_string(float_format=\"%.4f\"))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13",
   "language": "python",
   "name": "py313"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
